{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAqUV2E2hFoi"
      },
      "outputs": [],
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYoqUuh6VoSJ",
        "outputId": "2bd3db09-522a-4f89-c220-f3d73a3b1048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4ki1_e7XLc2"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = '/content/drive/MyDrive/Doutorado/Pesquisa/datasets/'\n",
        "PROJECT_PATH = '/content/drive/MyDrive/Doutorado/Pesquisa/'\n",
        "DATASET_NAME = \"tele_train\"\n",
        "TARGET = \"class\"\n",
        "SAMPLE = \"amostra\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2qUa8FDydwL",
        "outputId": "eeb166a2-af3f-41ee-c074-745ff8e8a75c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baW7cr47Y-RS",
        "outputId": "b591e71e-e077-4e8c-9176-d19a5090efa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gower in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gower) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gower) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5EnWc_yiIZ4",
        "outputId": "2338ae16-6582-4242-bf60-6fe931530a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.12.4)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn xgboost scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiAveqOQj9eR",
        "outputId": "4c05ea67-b3bc-4dea-b14b-4e98c7cdd397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyhard in /usr/local/lib/python3.11/dist-packages (2.2.4)\n",
            "Requirement already satisfied: pandas~=1.5.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn~=1.5.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (1.5.2)\n",
            "Requirement already satisfied: imbalanced-learn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (0.12.4)\n",
            "Requirement already satisfied: numpy~=1.23.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (1.23.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from pyhard) (6.0.2)\n",
            "Requirement already satisfied: scipy~=1.13.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (1.13.1)\n",
            "Requirement already satisfied: panel~=0.14.1 in /usr/local/lib/python3.11/dist-packages (from pyhard) (0.14.4)\n",
            "Requirement already satisfied: param<2.0.0,>=1.12.2 in /usr/local/lib/python3.11/dist-packages (from pyhard) (1.13.0)\n",
            "Requirement already satisfied: bokeh>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from pyhard) (2.4.3)\n",
            "Requirement already satisfied: holoviews>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (1.17.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from pyhard) (3.10.0)\n",
            "Requirement already satisfied: plotly>=5.9.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (5.24.1)\n",
            "Requirement already satisfied: plotting>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pyhard) (0.0.7)\n",
            "Requirement already satisfied: shapely~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (1.8.5.post1)\n",
            "Requirement already satisfied: hyperopt>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from pyhard) (0.2.7)\n",
            "Requirement already satisfied: pyispace>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from pyhard) (0.3.7)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (2.1.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (1.4.2)\n",
            "Requirement already satisfied: ncafs>=0.2 in /usr/local/lib/python3.11/dist-packages (from pyhard) (0.2.1)\n",
            "Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from pyhard) (0.15.2)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (24.2)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.11/dist-packages (from pyhard) (2.32.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from bokeh>=2.4.3->pyhard) (3.1.6)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh>=2.4.3->pyhard) (11.1.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.11/dist-packages (from bokeh>=2.4.3->pyhard) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from bokeh>=2.4.3->pyhard) (4.13.2)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.15.0->pyhard) (3.0.4)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.15.0->pyhard) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt>=0.2.4->pyhard) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt>=0.2.4->pyhard) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt>=0.2.4->pyhard) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt>=0.2.4->pyhard) (4.67.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt>=0.2.4->pyhard) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt>=0.2.4->pyhard) (0.10.9.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.11.0->pyhard) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->pyhard) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->pyhard) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->pyhard) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->pyhard) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->pyhard) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->pyhard) (2.8.2)\n",
            "Requirement already satisfied: setuptools>=52.0.0 in /usr/local/lib/python3.11/dist-packages (from ncafs>=0.2->pyhard) (75.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas~=1.5.0->pyhard) (2025.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from panel~=0.14.1->pyhard) (3.8)\n",
            "Requirement already satisfied: pyct>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from panel~=0.14.1->pyhard) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel~=0.14.1->pyhard) (6.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.9.0->pyhard) (9.1.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from plotting>=0.0.7->pyhard) (0.13.2)\n",
            "Requirement already satisfied: alphashape>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pyispace>=0.3.6->pyhard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.0->pyhard) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.0->pyhard) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.0->pyhard) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.0->pyhard) (2025.1.31)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.4.1->pyhard) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.4.1->pyhard) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.4.1->pyhard) (13.9.4)\n",
            "Requirement already satisfied: click-log>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from alphashape>=1.3.1->pyispace>=0.3.6->pyhard) (0.4.0)\n",
            "Requirement already satisfied: trimesh>=3.9.8 in /usr/local/lib/python3.11/dist-packages (from alphashape>=1.3.1->pyispace>=0.3.6->pyhard) (4.6.8)\n",
            "Requirement already satisfied: rtree>=0.9.7 in /usr/local/lib/python3.11/dist-packages (from alphashape>=1.3.1->pyispace>=0.3.6->pyhard) (1.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.9->bokeh>=2.4.3->pyhard) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.4.1->pyhard) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.4.1->pyhard) (2.18.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel~=0.14.1->pyhard) (0.5.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.4.1->pyhard) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyhard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf1duZ09XnhY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import logging\n",
        "import gower\n",
        "import collections\n",
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.datasets\n",
        "import math\n",
        "import os\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse.csgraph import minimum_spanning_tree\n",
        "from scipy.stats import iqr\n",
        "from sklearn import tree\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import DistanceMetric\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from abc import ABC, abstractmethod\n",
        "from sklearn.datasets import make_blobs\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler   # For oversampling\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.impute import KNNImputer\n",
        "from pyhard.classification import ClassifiersPool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c159FTA7fWfD"
      },
      "outputs": [],
      "source": [
        "base_bst = XGBClassifier(\n",
        "learning_rate=0.01,\n",
        "n_estimators=1000,\n",
        "max_depth=8,\n",
        "min_child_weight=1,\n",
        "gamma=0,\n",
        "subsample=0.8,\n",
        "colsample_bytree=0.8,\n",
        "objective='binary:logistic',\n",
        "eval_metric='logloss',\n",
        "scale_pos_weight=1,\n",
        "seed=27\n",
        ")\n",
        "\n",
        "colors = sns.color_palette(\"dark\")\n",
        "\n",
        "rosa = colors[6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDYyilxeYoIc"
      },
      "source": [
        "# **Importação da base treino/validação**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(DATASET_PATH + DATASET_NAME + '.csv',sep=',',encoding='utf-8')\n",
        "amostra = df.sample(n=1000,random_state=51)\n",
        "amostra.to_csv(DATASET_PATH + SAMPLE + '1.csv', index=False)"
      ],
      "metadata": {
        "id": "Vt7mPOFKu21T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ_vt-Xnd5YC"
      },
      "source": [
        "## Divisão das bases de treino e validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEzknD_Dfe_z"
      },
      "outputs": [],
      "source": [
        "class SamplesBuilder:\n",
        "    def __init__(self, csv_path, name, splits_dir=\"output_splits\"):\n",
        "        \"\"\"\n",
        "        Initialize the SamplesBuilder with a CSV path and output directory.\n",
        "\n",
        "        Parameters:\n",
        "        - csv_path (str): Path to the input CSV file.\n",
        "        - output_dir (str): Directory to save the generated splits.\n",
        "        \"\"\"\n",
        "        self.csv_path = csv_path\n",
        "        self.splits_dir = splits_dir\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.splits = {}  # To store train/validation splits for each seed\n",
        "        self.name = name\n",
        "\n",
        "        # Ensure the output directory exists\n",
        "        os.makedirs(self.splits_dir, exist_ok=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def impute_missing(train, n_neighbors=3):\n",
        "        \"\"\"\n",
        "        Static method to impute missing values using the K-nearest neighbors algorithm.\n",
        "        \"\"\"\n",
        "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
        "        imputed_data = imputer.fit_transform(train)\n",
        "        imputed_df = pd.DataFrame(imputed_data, columns=train.columns, index=train.index)\n",
        "        return imputed_df\n",
        "\n",
        "    def split_samples(self, seeds=[42, 43, 44, 45, 46]):\n",
        "        \"\"\"\n",
        "        Split the data into train and validation sets using multiple seeds and save them to CSV.\n",
        "\n",
        "        Parameters:\n",
        "        - seeds (list): List of random seeds to generate splits.\n",
        "        \"\"\"\n",
        "        for seed in seeds:\n",
        "            train, val = train_test_split(self.data, test_size=0.3, random_state=seed)\n",
        "\n",
        "            #train = self.ih_measure(train)\n",
        "\n",
        "            self.splits[seed] = {'train': train, 'validation': val}\n",
        "\n",
        "            # Save splits as CSV\n",
        "            train_path = os.path.join(self.splits_dir, f\"train_{self.name}_seed_{seed}.csv\")\n",
        "            val_path = os.path.join(self.splits_dir, f\"validation_{self.name}_seed_{seed}.csv\")\n",
        "\n",
        "            train.to_csv(train_path, index=False)\n",
        "            val.to_csv(val_path, index=False)\n",
        "\n",
        "\n",
        "        print(f\"Splits created and saved in '{self.splits_dir}' for seeds: {seeds}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMwVAv3YfxQX",
        "outputId": "a92299bc-5858-4448-917a-786eff1b7890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splits created and saved in '/content/drive/MyDrive/Doutorado/Pesquisa/datasets/splits' for seeds: [42, 43, 44, 45, 46]\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the class\n",
        "builder = SamplesBuilder(DATASET_PATH + SAMPLE + '1.csv', SAMPLE + '1', splits_dir= DATASET_PATH + \"splits\")\n",
        "\n",
        "# Generate splits and save them\n",
        "builder.split_samples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FvRvEGLYyUP"
      },
      "source": [
        "# **Criação das IHMs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc-4YgL7ZVnn"
      },
      "source": [
        "## Criação das classes que calculam as IHM unlabeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1khgeHxOqxx1"
      },
      "outputs": [],
      "source": [
        "class Measures(ABC):\n",
        "    \"\"\"\n",
        "    Base class for measures (aka meta-features). Each measure should be implemented as a separate method.\n",
        "    \"\"\"\n",
        "\n",
        "    _measures_dict: dict\n",
        "\n",
        "    @property\n",
        "    def logger(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _call_method(self, name, **kwargs):\n",
        "        return getattr(self, name)(**kwargs)\n",
        "\n",
        "    def calculate_all(self, measures_list=None):\n",
        "        if measures_list is None:\n",
        "            measures_list = self._measures_dict.keys()\n",
        "        elif isinstance(measures_list, list):\n",
        "            measures_list = sorted(list(set(measures_list) & set(self._measures_dict.keys())))\n",
        "        else:\n",
        "            raise TypeError(f\"Expected type list for parameter 'measures_list', not '{type(measures_list)}'\")\n",
        "\n",
        "        results = collections.OrderedDict()\n",
        "        for k in measures_list:\n",
        "            self.logger.info(f\"Calculating measure {repr(k)}\")\n",
        "            results[k] = self._call_method(self._measures_dict[k])\n",
        "\n",
        "        df_measures = pd.DataFrame(results)\n",
        "        return df_measures.add_prefix('feature_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97SM50Hlq2iF"
      },
      "outputs": [],
      "source": [
        "def minmax(f: np.ndarray, y: np.ndarray) -> float:\n",
        "    r\"\"\"\n",
        "    For binary classes, calculates :math:`\\min \\max (f_i) = \\min ( \\max (f^{c_1}_i), \\max (f^{c_2}_i) )`, where\n",
        "    :math:`f^{c_j}_i` is the i-th feature values for members of class :math:`c_j`.\n",
        "\n",
        "    Args:\n",
        "        f (array-like): i-th feature vector\n",
        "        y (array-like): corresponding class vector\n",
        "\n",
        "    Returns:\n",
        "        float: minmax value\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: If classes are not binary\n",
        "\n",
        "    \"\"\"\n",
        "    classes = np.unique(y)\n",
        "    assert len(classes) == 2\n",
        "    c1 = classes[0]\n",
        "    c2 = classes[1]\n",
        "    return min(np.max(f[y == c1]), np.max(f[y == c2]))\n",
        "\n",
        "def maxmin(f: np.ndarray, y: np.ndarray):\n",
        "    r\"\"\"\n",
        "    For binary classes, calculates :math:`\\max \\min (f_i) = \\max ( \\min (f^{c_1}_i), \\min (f^{c_2}_i) )`, where\n",
        "    :math:`f^{c_j}_i` is the i-th feature values for members of class :math:`c_j`.\n",
        "\n",
        "    Args:\n",
        "        f (array-like): i-th feature vector\n",
        "        y (array-like): corresponding class vector\n",
        "\n",
        "    Returns:\n",
        "        float: maxmin value\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: If classes are not binary\n",
        "\n",
        "    \"\"\"\n",
        "    classes = np.unique(y)\n",
        "    assert len(classes) == 2\n",
        "    c1 = classes[0]\n",
        "    c2 = classes[1]\n",
        "    return max(np.min(f[y == c1]), np.min(f[y == c2]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationMeasures(Measures):\n",
        "    \"\"\"\n",
        "    Hardness measures for classification. It provides separate methods to compute each measure.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): a dataframe where each line is an instace and columns are features. One column should\n",
        "            contain the labels. The name of the column with labels can be set with parameter `labels_col`\n",
        "        target_col (str): name of the column that contains the labels of the instances (default None - uses the\n",
        "            last column)\n",
        "        ccp_alpha (float): pruning parameter for pruned tree measures. If none is passed, then it attempts to tune\n",
        "            it automatically\n",
        "    \"\"\"\n",
        "\n",
        "    _measures_dict = {\n",
        "        'kDNadj': 'k_disagreeing_neighbors_adjusted',\n",
        "        'CLDadj': 'class_likeliood_diff_adjusted',\n",
        "        'DCPadj': 'disjunct_class_percentage_adjusted',\n",
        "        'DSadj': 'disjunct_size_adjusted',\n",
        "        'TD_Padj': 'tree_depth_pruned_adjusted',\n",
        "        'TD_Uadj': 'tree_depth_unpruned_adjusted',\n",
        "#        'F1adj': 'f1_adjusted',\n",
        "        'N2adj': 'intra_extra_ratio_adjusted'\n",
        "    }\n",
        "\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self, data: pd.DataFrame, target_col=None, ccp_alpha=None):\n",
        "        if target_col is None:\n",
        "            self.target_col = data.columns[-1]\n",
        "            self.y = data.iloc[:, -1]\n",
        "        else:\n",
        "            self.target_col = target_col\n",
        "            self.y = data[target_col]\n",
        "        self.data = data.reset_index(drop=True)\n",
        "        self.X = data.drop(columns=self.target_col)\n",
        "        self.N = len(data)\n",
        "\n",
        "        seed = np.random.seed(55)\n",
        "\n",
        "        # Gower distance matrix\n",
        "        self.dist_matrix_gower = gower.gower_matrix(self.X.values.copy())\n",
        "        #self.dist_matrix_gower = gower_distance(self.X)\n",
        "        delta = np.diag(-np.ones(self.dist_matrix_gower.shape[0]))\n",
        "        self.indices_gower = np.argsort(self.dist_matrix_gower + delta, axis=1)\n",
        "        self.distances_gower = np.sort(self.dist_matrix_gower, axis=1)\n",
        "\n",
        "        self.dot = None\n",
        "\n",
        "        # Naive Bayes classifier\n",
        "        n_c = self.y.nunique()\n",
        "        priors = np.ones((n_c,)) / n_c\n",
        "\n",
        "        nb = GaussianNB()#priors=priors\n",
        "        self.calibrated_nb = CalibratedClassifierCV(\n",
        "            estimator=nb,\n",
        "            method='sigmoid',\n",
        "            cv=3,\n",
        "            ensemble=False,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        self.calibrated_nb.fit(self.X, self.y)\n",
        "\n",
        "###################################################################################################################################\n",
        "\n",
        "    def k_disagreeing_neighbors_adjusted(self, k: int = 10, distance: str = 'gower') -> np.ndarray:\n",
        "        r\"\"\"\n",
        "        k-Disagreeing Neighbors Adjusted (kDNadj) gives the percentage of the :math:`k` nearest neighbors of :math:`\\\\mathbf x_i`\n",
        "        which do not share its label.\n",
        "\n",
        "        .. math::\n",
        "\n",
        "            kDNadj(\\mathbf{x_i}) = \\frac{ \\sharp \\{\\mathbf x_j | \\mathbf x_j \\in kNN(\\mathbf x_i) \\wedge y_j\n",
        "            \\neq y_i\\}}{k}\n",
        "\n",
        "        Args:\n",
        "            k (int): number of neighbors\n",
        "            distance (str): distance metric (default 'gower')\n",
        "\n",
        "        Returns:\n",
        "            array-like: :math:`kDNadj(\\mathbf x_i)`\n",
        "        \"\"\"\n",
        "        data = self.data.copy()\n",
        "        if distance == 'gower':\n",
        "            indices = self.indices_gower[:, :k + 1]\n",
        "        else:\n",
        "            nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='auto').fit(self.X)\n",
        "            distances, indices = nbrs.kneighbors(self.X)\n",
        "\n",
        "        unique_values = pd.unique(data[self.target_col])\n",
        "        C = [[] for _ in unique_values]\n",
        "        vl_unico = sorted(unique_values.tolist())\n",
        "\n",
        "        last_data_index = len(data) -1\n",
        "\n",
        "        for j in vl_unico:\n",
        "          for i in range(0, len(data)):\n",
        "              v = data.loc[indices[i]][self.target_col].values\n",
        "              C[j].append(np.sum(v[1:] == vl_unico[j]) / k)\n",
        "\n",
        "        kDNadj = []\n",
        "        for i in range(len(C[0])):\n",
        "          entropy = 0.0\n",
        "          p = [c[i] for c in C]\n",
        "          entropy -= sum(p * math.log2(p) if p > 0 else 0 for p in p)\n",
        "          kDNadj.append(entropy)\n",
        "\n",
        "        return kDNadj\n",
        "\n",
        "\n",
        "###################################################################################################################################\n",
        "\n",
        "    def intra_extra_ratio_adjusted(self, distance='gower') -> np.ndarray:\n",
        "        r\"\"\"\n",
        "        Ratio of the intra-class and extra-class distances (N2): first the ratio of the distance of :math:`\\mathbf x_i`\n",
        "        to the nearest example from its class to the distance it has to the nearest instance from a different class\n",
        "        (aka nearest enemy) is computed:\n",
        "\n",
        "        .. math::\n",
        "\n",
        "            IntraInter(\\mathbf x_i) = \\frac{d(\\mathbf x_i,NN(\\mathbf x_i) \\in y_i)}{d(\\mathbf x_i, ne(\\mathbf x_i))}\n",
        "\n",
        "        where :math:`NN(\\mathbf x_i)` represents a nearest neighbor of :math:`\\mathbf x_i` and :math:`ne(\\mathbf x_i)`\n",
        "        is the nearest enemy of :math:`\\mathbf x_i`:\n",
        "\n",
        "        .. math::\n",
        "\n",
        "            ne(\\mathbf x_i) = NN(\\mathbf x_i) \\in y_j \\neq y_i\n",
        "\n",
        "        Then :math:`N_2` is taken as:\n",
        "\n",
        "        .. math::\n",
        "\n",
        "            N_2(\\mathbf x_i) = 1 - \\frac{1}{IntraInter(\\mathbf x_i) + 1}\n",
        "\n",
        "        Larger values of :math:`N2(\\mathbf x_i)` indicate that the instance :math:`\\mathbf x_i` is closer to an example\n",
        "        from another class than to an example from its own class and is, therefore, harder to classify.\n",
        "\n",
        "        Args:\n",
        "            distance (str): the distance metric to use (default `'gower'`). See `this link\n",
        "                <https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html\n",
        "                #sklearn.neighbors.DistanceMetric>`_ for a list of available metrics.\n",
        "\n",
        "        Returns:\n",
        "            array-like: :math:`N_2(\\mathbf x_i)`\n",
        "        \"\"\"\n",
        "        y = self.y.copy()\n",
        "\n",
        "        if distance == 'gower':\n",
        "            indices = self.indices_gower\n",
        "            distances = self.distances_gower\n",
        "        else:\n",
        "            nbrs = NearestNeighbors(n_neighbors=len(self.y), algorithm='auto', metric=distance).fit(self.X)\n",
        "            distances, indices = nbrs.kneighbors(self.X)\n",
        "\n",
        "        N2 = np.zeros(y.values.shape)\n",
        "        for i, label in y.items():\n",
        "            nn = y.loc[indices[i, :]]\n",
        "            nn1 = nn.iloc[1]\n",
        "            intra = nn.eq(nn)\n",
        "            extra = nn.ne(nn1)\n",
        "            assert np.all(np.diff(distances[i, intra]) >= 0)\n",
        "            assert np.all(np.diff(distances[i, extra]) >= 0)\n",
        "            N2[i] = distances[i, intra][1] / max(distances[i, extra][1], 1e-15)\n",
        "        return N2\n",
        "\n",
        "###################################################################################################################################\n",
        "\n",
        "    def class_likeliood_diff_adjusted(self) -> np.ndarray:\n",
        "        r\"\"\"\n",
        "        Class Likelihood Difference (CLD) takes the difference between the likelihood of :math:`\\mathbf x_i` in\n",
        "        relation to its class and the maximum likelihood it has to any other class.\n",
        "\n",
        "        .. math::\n",
        "\n",
        "            CLD(\\mathbf x_i) = \\frac{1 -\\left (P(\\mathbf x_i|y_i)P(y_i) - \\max_{y_j \\neq y_i}\n",
        "            [P(\\mathbf x_i |y_j)P(y_j)]\\right )}{2}\n",
        "\n",
        "        The difference in the class likelihood is larger for easier instances, because the confidence it belongs to its\n",
        "        class is larger than that of any other class. We take the complement of the measure as indicated in the\n",
        "        equation above.\n",
        "\n",
        "        Returns:\n",
        "            array-like: :math:`CLD(\\mathbf x_i)`\n",
        "        \"\"\"\n",
        "        data = self.data.copy()\n",
        "        proba = self.calibrated_nb.predict_proba(self.X)\n",
        "        array_of_lists = np.array(proba)\n",
        "\n",
        "        max_indices = np.argsort(array_of_lists, axis=1)[:, -2:]\n",
        "        largest_values = array_of_lists[np.arange(array_of_lists.shape[0])[:, None], max_indices]\n",
        "        subtraction_result = (largest_values[:, 0] - largest_values[:, 1]) * (-1)\n",
        "\n",
        "        resultados = subtraction_result.reshape(-1)\n",
        "\n",
        "        return (1 - np.array(resultados)) / 2\n",
        "\n",
        "\n",
        "###################################################################################################################################\n",
        "\n",
        "    def disjunct_class_percentage_adjusted(self,target_col=None,ccp_alpha=None) -> np.ndarray:\n",
        "        r\"\"\"\n",
        "        Disjunct Class Percentage (DCP) builds a decision tree using :math:`\\mathcal{D}` and considers the percentage\n",
        "        of instances in the disjunct of :math:`\\mathbf x_i` which share the same label as :math:`\\mathbf x_i`.\n",
        "        The disjunct of an example corresponds to the leaf node where it is classified by the decision tree.\n",
        "\n",
        "        .. math::\n",
        "\n",
        "            DCP(\\mathbf x_i) = 1- \\frac{\\sharp\\{\\mathbf x_j | \\mathbf x_j \\in Disjunct(\\mathbf x_i) \\wedge y_j = y_i\\}}\n",
        "            {\\sharp\\{\\mathbf x_j|\\mathbf x_j \\in Disjunct(\\mathbf x_i)\\}}\n",
        "\n",
        "        Returns:\n",
        "            array-like: :math:`DCP(\\mathbf x_i)`\n",
        "        \"\"\"\n",
        "        data = self.data.copy()\n",
        "        seed = np.random.seed(55)\n",
        "\n",
        "          #rodar a metodologia do HM com a estimativa do y\n",
        "          #Decision Tree Classifier Pruned\n",
        "        df_dcp = data.copy()\n",
        "        if target_col is None:\n",
        "          target_col = df_dcp.columns[-1]\n",
        "          y = df_dcp.iloc[:, -1]\n",
        "        else:\n",
        "          target_col = target_col\n",
        "          y = df_dcp[target_col]\n",
        "        df_dcp = df_dcp.reset_index(drop=True)\n",
        "        X = df_dcp.drop(columns=target_col)\n",
        "\n",
        "        if ccp_alpha is None:\n",
        "            parameters = {'ccp_alpha': np.linspace(0.001, 0.1, num=100)}\n",
        "            dtc = tree.DecisionTreeClassifier(criterion='gini', random_state=seed)\n",
        "            clf = GridSearchCV(dtc, parameters, n_jobs=-1)\n",
        "            clf.fit(X.values, y.values)\n",
        "            ccp_alpha = clf.best_params_['ccp_alpha']\n",
        "\n",
        "        dtc_pruned = tree.DecisionTreeClassifier(criterion='gini', ccp_alpha=ccp_alpha, random_state=seed)\n",
        "        dtc_pruned = dtc_pruned.fit(X.values, y.values)\n",
        "\n",
        "        df_dcp['leaf_id'] = dtc_pruned.apply(X.values)\n",
        "\n",
        "        unique_values = pd.unique(y)\n",
        "        C = [[] for _ in unique_values]\n",
        "        vl_unico = sorted(unique_values.tolist())\n",
        "\n",
        "        for j in vl_unico:\n",
        "            for index, row in df_dcp.iterrows():\n",
        "              df_leaf = df_dcp[df_dcp['leaf_id'] == row['leaf_id']]\n",
        "              if row[TARGET] == vl_unico[j]:\n",
        "                C[j].append(len(df_leaf[df_leaf[TARGET] == row[TARGET]]) / len(df_leaf))\n",
        "              else:\n",
        "                C[j].append(len(df_leaf[df_leaf[TARGET] == vl_unico[j]]) / len(df_leaf))\n",
        "\n",
        "        DCPadj = []\n",
        "        for n in range(len(C[0])):\n",
        "          entropy = 0.0\n",
        "          p = [c[n] for c in C]\n",
        "          entropy -= sum(p * math.log2(p) if p > 0 else 0 for p in p)\n",
        "          DCPadj.append(entropy)\n",
        "        return DCPadj\n",
        "\n",
        "\n",
        "###################################################################################################################################\n",
        "\n",
        "    def disjunct_size_adjusted(self,target_col=None) -> np.ndarray:\n",
        "\n",
        "        data = self.data.copy()\n",
        "        seed = np.random.seed(55)\n",
        "\n",
        "        df_ds = data.copy()\n",
        "        train_sample = data.drop(data.index[-1])\n",
        "\n",
        "          #rodar a metodologia do HM com a estimativa do y\n",
        "          #Decision Tree Classifier\n",
        "        if target_col is None:\n",
        "          target_col = df_ds.columns[-1]\n",
        "          y = df_ds.iloc[:, -1]\n",
        "        else:\n",
        "          target_col = target_col\n",
        "          y = df_ds[target_col]\n",
        "        df_ds = df_ds.reset_index(drop=True)\n",
        "        X = df_ds.drop(columns=target_col)\n",
        "\n",
        "        dtc = tree.DecisionTreeClassifier(min_samples_split=2, criterion='gini', random_state=seed)\n",
        "        dtc = dtc.fit(X.values, y.values)\n",
        "\n",
        "        df_ds['leaf_id'] = dtc.apply(X.values)\n",
        "        df_count = df_ds.groupby('leaf_id').count().iloc[:, 0].to_frame('count').subtract(1) #iloc referencia a posição da linha/coluna. loc retorna o label da linha/coluna\n",
        "          #aqui, iloc fixando primeira coluna, varrendo todas as linhas\n",
        "        df_ds = df_ds.join(df_count, on='leaf_id')\n",
        "        DSadj = df_ds['count'].divide(df_ds['count'].max())\n",
        "          #pd.set_option('display.max_rows', data.shape[0]+1)\n",
        "          #print(data)\n",
        "\n",
        "        return 1 - DSadj.values\n",
        "\n",
        "###################################################################################################################################\n",
        "\n",
        "\n",
        "    def tree_depth_unpruned_adjusted(self,target_col=None) -> np.ndarray:\n",
        "        r\"\"\"\n",
        "        Tree Depth (TD) returns the depth of the leaf node that classifies :math:`\\mathbf x_i` in a  decision tree,\n",
        "        normalized by the maximum depth of the tree built from :math:`D`:\n",
        "\n",
        "        .. math::\n",
        "\n",
        "            TD(\\mathbf x_i) = \\frac{depth(\\mathbf x_i)}{\\max(depth(D))}\n",
        "\n",
        "        There are two versions of this measure, using pruned (:math:`TD_P(\\mathbf x_i)`)\n",
        "        and unpruned (:math:`TD_U(\\mathbf x_i)`) decision trees. Instances harder to classify tend to be placed\n",
        "        at deeper levels of the trees and present higher :math:`TD` values.\n",
        "\n",
        "        Returns:\n",
        "            array-like: :math:`TD_U(\\mathbf x_i)`\n",
        "        \"\"\"\n",
        "        data = self.data.copy()\n",
        "        seed = np.random.seed(55)\n",
        "\n",
        "        df_ds = data.copy()\n",
        "        train_sample = data.drop(data.index[-1])\n",
        "\n",
        "          #rodar a metodologia do HM com a estimativa do y\n",
        "          #Decision Tree Classifier\n",
        "        if target_col is None:\n",
        "          target_col = df_ds.columns[-1]\n",
        "          y = df_ds.iloc[:, -1]\n",
        "        else:\n",
        "          target_col = target_col\n",
        "          y = df_ds[target_col]\n",
        "        df_ds = df_ds.reset_index(drop=True)\n",
        "        X = df_ds.drop(columns=target_col)\n",
        "\n",
        "        dtc = tree.DecisionTreeClassifier(min_samples_split=2, criterion='gini', random_state=seed)\n",
        "        dtc = dtc.fit(X.values, y.values)\n",
        "\n",
        "        TDUadj = X.apply(lambda x: dtc.decision_path([x]).sum() - 1, axis=1, raw=True).values / dtc.get_depth()\n",
        "\n",
        "        return TDUadj\n",
        "\n",
        "###################################################################################################################################\n",
        "\n",
        "    def tree_depth_pruned_adjusted(self,target_col=None,ccp_alpha=None) -> np.ndarray:\n",
        "        r\"\"\"\n",
        "        Tree Depth (TD) returns the depth of the leaf node that classifies :math:`\\mathbf x_i` in a  decision tree,\n",
        "        normalized by the maximum depth of the tree built from :math:`D`:\n",
        "\n",
        "        .. math::\n",
        "\n",
        "            TD(\\mathbf x_i) = \\frac{depth(\\mathbf x_i)}{\\max(depth(D))}\n",
        "\n",
        "        There are two versions of this measure, using pruned (:math:`TD_P(\\mathbf x_i)`)\n",
        "        and unpruned (:math:`TD_U(\\mathbf x_i)`) decision trees. Instances harder to classify tend to be placed\n",
        "        at deeper levels of the trees and present higher :math:`TD` values.\n",
        "\n",
        "        Returns:\n",
        "            array-like: :math:`TD_P(\\mathbf x_i)`\n",
        "        \"\"\"\n",
        "\n",
        "        data = self.data.copy()\n",
        "        seed = np.random.seed(55)\n",
        "\n",
        "        df_dcp = data.copy()\n",
        "        train_sample = data.drop(data.index[-1])\n",
        "\n",
        "          #rodar a metodologia do HM com a estimativa do y\n",
        "          #Decision Tree Classifier Pruned\n",
        "        if target_col is None:\n",
        "          target_col = df_dcp.columns[-1]\n",
        "          y = df_dcp.iloc[:, -1]\n",
        "        else:\n",
        "          target_col = target_col\n",
        "          y = df_dcp[target_col]\n",
        "        df_dcp = df_dcp.reset_index(drop=True)\n",
        "        X = df_dcp.drop(columns=target_col)\n",
        "\n",
        "        if ccp_alpha is None:\n",
        "            parameters = {'ccp_alpha': np.linspace(0.001, 0.1, num=100)}\n",
        "            dtc = tree.DecisionTreeClassifier(criterion='gini', random_state=seed)\n",
        "            clf = GridSearchCV(dtc, parameters, n_jobs=-1)\n",
        "            clf.fit(X.values, y.values)\n",
        "            ccp_alpha = clf.best_params_['ccp_alpha']\n",
        "\n",
        "        dtc_pruned = tree.DecisionTreeClassifier(criterion='gini', ccp_alpha=ccp_alpha, random_state=seed)\n",
        "        dtc_pruned = dtc_pruned.fit(X.values, y.values)\n",
        "\n",
        "        TDPadj = X.apply(lambda x: dtc_pruned.decision_path([x]).sum() - 1, axis=1, raw=True).values / dtc_pruned.get_depth()\n",
        "\n",
        "        return TDPadj\n"
      ],
      "metadata": {
        "id": "m_3fXAtWHHx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMXW9s3scyZ4"
      },
      "source": [
        "## Aplicação nos conjuntos de treino"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hm_seed = []\n",
        "for seed, splits in builder.splits.items():\n",
        "    validation_data = splits['validation']\n",
        "\n",
        "    for index, row in validation_data.iterrows():\n",
        "        current_train = splits['train'].copy()\n",
        "        current_train = pd.concat([current_train, pd.DataFrame([row])], ignore_index=True)\n",
        "        #modified_train_sets.append(current_train)\n",
        "\n",
        "        # Separate numerical features for KNN imputation\n",
        "        numerical_features = current_train.select_dtypes(include=np.number).columns.tolist()\n",
        "        modified_train_set_numerical = current_train[numerical_features]\n",
        "\n",
        "        # Apply KNN imputation to the numerical features\n",
        "        imputed_modified_train_set = SamplesBuilder.impute_missing(modified_train_set_numerical)\n",
        "\n",
        "        # Replace the original numerical columns with the imputed ones\n",
        "        current_train[numerical_features] = imputed_modified_train_set\n",
        "        current_train[TARGET] = current_train[TARGET].astype(int)\n",
        "\n",
        "        m = ClassificationMeasures(current_train)\n",
        "        df_meta_feat = m.calculate_all()\n",
        "        df_hm = pd.DataFrame(df_meta_feat, columns=['feature_kDNadj'])\n",
        "#        df_hm = pd.DataFrame(df_meta_feat, columns=['feature_kDNadj','feature_N2adj','feature_CLDadj','feature_DCPadj','feature_DSadj','feature_TD_Uadj','feature_TD_Padj'])\n",
        "\n",
        "        # Get the last row of the current df_hm\n",
        "        last_row = df_hm.tail(1).copy()\n",
        "\n",
        "        # Add a column to identify the seed\n",
        "        last_row['seed'] = seed\n",
        "\n",
        "        # Append the last row to the list of DataFrames to stack\n",
        "        df_hm_seed.append(last_row)\n",
        "\n",
        "# Concatenate all the DataFrames in the list into a single DataFrame\n",
        "df_hm_final = pd.concat(df_hm_seed, ignore_index=True)\n",
        "\n",
        "# Now you have 'stacked_df' which contains the last row of each df_hm with seed information.\n",
        "print(df_hm_final.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9l3eTiDTdwr",
        "outputId": "72bb68fd-b574-4c62-b703-6d7eedfc3eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n",
            "INFO:__main__:Calculating measure 'TD_Uadj'\n",
            "INFO:__main__:Calculating measure 'N2adj'\n",
            "INFO:__main__:Calculating measure 'kDNadj'\n",
            "INFO:__main__:Calculating measure 'CLDadj'\n",
            "INFO:__main__:Calculating measure 'DCPadj'\n",
            "INFO:__main__:Calculating measure 'DSadj'\n",
            "INFO:__main__:Calculating measure 'TD_Padj'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NdiBkK0dg-B"
      },
      "source": [
        "## Base com as metafeatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbATwuqyJu0A"
      },
      "outputs": [],
      "source": [
        "df_hm_final.to_csv(PROJECT_PATH + 'df_hm_' + DATASET_NAME + SAMPLE + '1.csv', sep=',', encoding='utf-8')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}